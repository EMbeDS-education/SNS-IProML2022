{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font size=\"+4\">IProML 2021/2022</font></center>\n",
    "<center><font size=\"+4\">Introduction to Programming and</font></center>\n",
    "<center><font size=\"+4\">Machine Learning in Python</font></center>\n",
    "<center><font size=\"+2\">Scuola Normale Superiore, Pisa, Italy</font></center>\n",
    "\n",
    "<center><font size=\"+2\">Course responsibles</font></center>\n",
    "<center><font size=\"+2\">Andrea Vandin a.vandin@santannapisa.it</font></center>\n",
    "<center><font size=\"+2\">Daniele Licari d.licari@santannapisa.it</font></center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrkbsmwRhuWe"
   },
   "source": [
    "<center><font size=\"+4\">Lecture 5: </font></center>\n",
    "<center><font size=\"+2\"> Creation of word clouds for COVID-related online news</font></center>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isBU8c9fhuWg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xkGN1b3huWg"
   },
   "source": [
    "# Computing and visualizing the most important words in online news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXy-eVmEhuWh"
   },
   "source": [
    "This example shows that functions can hide a lot of complexity.\n",
    "* E.g., we can download remote data by just invoking a function\n",
    "* In particular, in this example we will:\n",
    "    1.\tDownload all the articles the online service [NewsAPI](https://newsapi.org/)\n",
    "    2.\tCombine the articles into one document (`str`)\n",
    "    3.\tClean data (removing punctuation and stopwords)\n",
    "    4.\tCompute word-frequency pairs\n",
    "    5.\tVisualize the analysis in a Word Cloud\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Some definitions:*\n",
    "\n",
    "A **web service** is an application run by a web server that can be called from a series of URLs that will return their data in a format intended for parsing by a \"generic\" computer program rather than by a browser. As a result, web services can use something like XML (especially SOAP or so) or JSON is used.\n",
    "\n",
    "An **Application Programming Interface (API)** allows two systems to communicate with one another. An API exactly defines the methods for one software program to interact with the other. \n",
    "\n",
    "![](images/web_server_web_service.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxDJuJC9huWk"
   },
   "source": [
    "## The modules we need to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "onPRcvz2huWl",
    "outputId": "32669025-bfbc-4a6c-e869-e46b8a9f8956",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python client library to integrate News API into your Python application\n",
    "%pip install newsapi-python\n",
    "# Python module for WordCloud\n",
    "%pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Z_n5daChuWm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Python client to integrate News API into our Python application \n",
    "from newsapi import NewsApiClient \n",
    "\n",
    "# for creating wordclouds into your Python application \n",
    "from wordcloud import WordCloud \n",
    "\n",
    "# Import Matplotlib for visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJv2ycUJhuWo"
   },
   "source": [
    "## Download Articles using NewsApi Client\n",
    "\n",
    "__NewsApiClient__ is a local client for the online service [__NewsAPI__](https://newsapi.org/) that allows you to get news from [eveywhere in the world](https://newsapi.org/sources)\n",
    "* Intuitively, an online service is like an online function running in a remote server (computer)\n",
    "* A local client is a piece of code runnning in your machine that communicates with the online service\n",
    "  * It allows you to easily interact with the online service\n",
    "  * The interaction is typically done through a set of message exchanges as prescribed by the APIs of the service\n",
    "* We need a `api_key` that is a univoque identifier \n",
    "  * necessary when making requests to be identified\n",
    "  * can be obtained registering [here](https://newsapi.org/register)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VyscgnVIYpFA"
   },
   "source": [
    "There exist many online services accessible with Python (e.g. [Twitter API](https://www.tweepy.org/))\n",
    "* Most of them follow this api-key approach\n",
    "* E.g. to enforce subscriptions\n",
    "<!-- * In our case, __we are using a free subscription that allows us to only get the first 250 characters from a news item__ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNPcmrzohuWt"
   },
   "source": [
    "### Using the Python NewsAPI Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlUhhhK9huWt"
   },
   "source": [
    "We want to get **100 most relevant** articles about **coronavirus**, published in **usa-today** using [Everything NewsAPI service](https://newsapi.org/docs/endpoints/everything)\n",
    "<!-- * This looks like a [normal function invocation](https://newsapi.org/docs/client-libraries/python) -->\n",
    "<!-- * But under the hood a lot happens to contact the remote service \n",
    "(https://newsapi.org/v2/everything?q=coronavirus&sources=usa-today&language=en&pageSize=100&sortBy=relevancy&apiKey=345f8a0aa8c64d549fde1d8343d036f8) -->\n",
    "\n",
    "\n",
    "Luckily, the function `<NewsApiClient>.get_everything` hides complexity to us\n",
    " - It uses the parameters chosen by the user to create the request to the online service.\n",
    " (es. https://newsapi.org/v2/everything?q=coronavirus&sources=usa-today&language=en&pageSize=100&sortBy=relevancy&apiKey=345f8a0aa8c64d549fde1d8343d036f8)\n",
    " - Transforms the service response into a data type that can be easily manipulated in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Whc4M8nhuWu"
   },
   "outputs": [],
   "source": [
    "# create and initialize the client with your API key:\n",
    "newsapi = NewsApiClient(api_key='345f8a0aa8c64d549fde1d8343d036f8')\n",
    "\n",
    "# use remote service and get results\n",
    "json_data = newsapi.get_everything( q='coronavirus',         # All the articles that contain this word\n",
    "                                    language='en',          # in English\n",
    "                                    sources = 'usa-today',  # from usa-today (newspaper of interest)\n",
    "                                    page_size=100,          # Get 100 articles\n",
    "                                    sort_by='relevancy'     # order by relevancy (more closely related to q)\n",
    "                                    )\n",
    "# There exist many more parameters allowing us the ask for more articles, different sources (eg.'cnn, bbc-news,the-verge'), etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwuXEhVShuWv"
   },
   "source": [
    "The return value `json_data` is just a dictionary collecting information about the remote request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9lBSMEehuWv",
    "outputId": "691d24ea-c776-4a24-fcad-85552f9a2988"
   },
   "outputs": [],
   "source": [
    "print(type(json_data))\n",
    "print()\n",
    "print(json_data.keys())\n",
    "print()\n",
    "print('The status of the request is',json_data['status'],'There are ',json_data['totalResults'],'articles matching the request.')\n",
    "print('We got',len(json_data['articles']),'articles')\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMSGhhuqhuWy"
   },
   "source": [
    "We can ignore all the metadata (i.e. the data about the remote request) and focus on the actual articles only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGJecHG2huWy",
    "outputId": "023d913b-9d6a-40e0-ccd4-d6e4c4487157"
   },
   "outputs": [],
   "source": [
    "# get articles \n",
    "articles = json_data['articles'] \n",
    "\n",
    "# Get the description of the first article\n",
    "content = articles[0]['description']\n",
    "print('The content:')\n",
    "print(content)\n",
    "print('The content is long',len(content),\"characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Let's implement the first function to avoid writing spaghetti code. We can use it to receive news from different topics (eg. 'Ukraine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_relevant_online_news(query: str,  source:str='usa-today', n_articles:int=100, language:str='en') -> list:\n",
    "\n",
    "def get_relevant_online_news(query,  source='usa-today', n_articles=100, language='en'):\n",
    "    \"\"\"\n",
    "    Download relevant 'n_articles' news that contain 'query' word from 'source' newspaper in 'language' language  using NewsAPI\n",
    "    \n",
    "    :param query: \n",
    "        str, keywords or phrases to search for in the news title and body.\n",
    "    :param source: \n",
    "        str, the news source or blog you want news from  (default 'usa-today')\n",
    "    :param n_articles: \n",
    "        int, the number of articles to return (default 100)\n",
    "    :param language: \n",
    "        str, the language you want to get news\n",
    "    :return: \n",
    "        list, list of articles\n",
    "    ---\n",
    "    Usage:\n",
    "        # get top 50 relevant news from CNN about Ukraine\n",
    "        articles = get_relevant_online_news('Ukraine', source='cnn',n_news=50)\n",
    "    \"\"\"\n",
    "\n",
    "    # create and initialize the client with your API key:\n",
    "    newsapi = NewsApiClient(api_key='345f8a0aa8c64d549fde1d8343d036f8')\n",
    "\n",
    "    # use remote service and get results\n",
    "    json_data = newsapi.get_everything(q=query,                 # All the articles that contain 'query' word\n",
    "                                        language=language,      #  the language you want to get news\n",
    "                                        sources = source,       # from news source\n",
    "                                        page_size=n_articles,   # Get  number of articles\n",
    "                                        sort_by='relevancy'     # order by relevancy (more closely related to q)\n",
    "                                        )\n",
    "    # get articles \n",
    "    articles = json_data['articles'] \n",
    "    \n",
    "    return articles\n",
    "\n",
    "# Python docstrings are strings used to document our code after the definition of a function, method, class, or module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_relevant_online_news.__doc__)\n",
    "help(get_relevant_online_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles = get_relevant_online_news('Ukraine')\n",
    "articles = get_relevant_online_news('coronavirus')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWzx75OtYpFL"
   },
   "source": [
    "## Combine the articles into one document \n",
    "Now let's combine the description of all the news into variable `contents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5-qaKrK_huWz",
    "outputId": "c961b973-6427-4ee1-ec2c-975ec2fe6706"
   },
   "outputs": [],
   "source": [
    "def combine_articles(list_of_articles):\n",
    "    \"\"\" \n",
    "    It concatenates the description of the news (passed as a parameter) in a string.\n",
    "    \n",
    "    :param list_of_articles:\n",
    "        list of articles downloaded from NewAPI\n",
    "    :return:\n",
    "        a string that contains all the news descriptions\n",
    "    \"\"\"\n",
    "    contents = ''\n",
    "    for article in list_of_articles:\n",
    "         #  check if key 'description' has Non-None value in dictionary \n",
    "        if article['description']:\n",
    "            contents += article['description']+\" \"\n",
    "            \n",
    "    return contents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_descriptions = combine_articles(articles)\n",
    "print('Overall we have',len(all_descriptions),'characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean the data removing not interesting words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6XRBgRzhuWq",
    "toc-hr-collapsed": true
   },
   "source": [
    "### Implementing two functions for data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhqbA-ZdhuWr"
   },
   "source": [
    "**we want to ignore punctuation** for the analysis\n",
    "* We are going to use it to delete all punctuation from a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjYmoOxBhuWs"
   },
   "outputs": [],
   "source": [
    "# sets of punctuation\n",
    "PUNCTUATION = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "\n",
    "# to remove Punctuations from a string\n",
    "def remove_punctuations(my_str): \n",
    "    \"\"\" \n",
    "    It removes punctuations from the string 'my_str'\n",
    "    \n",
    "    :param list_of_articles:\n",
    "        string with punctuation to remove \n",
    "    :return:\n",
    "        new string without punctuation\n",
    "    \"\"\"\n",
    "    str_no_punct = \"\"\n",
    "    for char in my_str:\n",
    "        if char not in PUNCTUATION:\n",
    "            str_no_punct = str_no_punct + char\n",
    "    return str_no_punct\n",
    "\n",
    "# for testing\n",
    "str_no_punct = remove_punctuations('Andrea likes pizza and Python!! and you?')\n",
    "str_no_punct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Stop words__ are usually the most common words in any text ( like “the”, “of”, “to” and “and”), \n",
    "<!-- Prepositions, Determiners, Conjunctions -->\n",
    "* They don’t tell us much about the actual content in a text\n",
    "* These are the words we want to ignore - this is our data cleaning\n",
    " \n",
    "We want to find the words that will help us differentiate a text from texts that are about different subjects. \n",
    "* __We will filter out the common words__.\n",
    "* Of course, we are going to use a function for doing this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of English stopwords\n",
    "STOPWORDS = {\"about\",\"above\",\"across\",\"after\",\"again\",\"against\",\"all\",\"almost\",\"alone\",\"along\",\"already\",\"also\",\"although\",\"always\",\"am\",\"among\",\"an\",\"and\",\"another\",\"any\",\"anyone\",\"anything\",\"anywhere\",\"are\",\"aren't\",\"around\",\"as\",\"at\",\"b\",\"B\",\"back\",\"be\",\"became\",\"because\",\"become\",\"becomes\",\"been\",\"before\",\"behind\",\"being\",\"below\",\"between\",\"both\",\"but\",\"by\",\"c\",\"C\",\"can\",\"cannot\",\"can't\",\"could\",\"couldn't\",\"d\",\"D\",\"did\",\"didn't\",\"do\",\"does\",\"doesn't\",\"doing\",\"done\",\"don't\",\"down\",\"during\",\"e\",\"E\",\"each\",\"either\",\"enough\",\"even\",\"ever\",\"every\",\"everyone\",\"everything\",\"everywhere\",\"f\",\"F\",\"few\",\"find\",\"first\",\"for\",\"four\",\"from\",\"full\",\"further\",\"g\",\"G\",\"get\",\"give\",\"go\",\"h\",\"H\",\"had\",\"hadn't\",\"has\",\"hasn't\",\"have\",\"haven't\",\"having\",\"he\",\"he'd\",\"he'll\",\"her\",\"here\",\"here's\",\"hers\",\"herself\",\"he's\",\"him\",\"himself\",\"his\",\"how\",\"however\",\"how's\",\"i\",\"I\",\"i'd\",\"if\",\"i'll\",\"i'm\",\"in\",\"interest\",\"into\",\"is\",\"isn't\",\"it\",\"it's\",\"its\",\"itself\",\"i've\",\"j\",\"J\",\"k\",\"K\",\"keep\",\"l\",\"L\",\"last\",\"least\",\"less\",\"let's\",\"m\",\"M\",\"made\",\"many\",\"may\",\"me\",\"might\",\"more\",\"most\",\"mostly\",\"much\",\"must\",\"mustn't\",\"my\",\"myself\",\"n\",\"N\",\"never\",\"next\",\"no\",\"nobody\",\"noone\",\"nor\",\"not\",\"nothing\",\"now\",\"nowhere\",\"o\",\"O\",\"of\",\"off\",\"often\",\"on\",\"once\",\"one\",\"only\",\"or\",\"other\",\"others\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"p\",\"P\",\"part\",\"per\",\"perhaps\",\"put\",\"q\",\"Q\",\"r\",\"R\",\"rather\",\"s\",\"S\",\"same\",\"see\",\"seem\",\"seemed\",\"seeming\",\"seems\",\"several\",\"shan't\",\"she\",\"she'd\",\"she'll\",\"she's\",\"should\",\"shouldn't\",\"show\",\"side\",\"since\",\"so\",\"some\",\"someone\",\"something\",\"somewhere\",\"still\",\"such\",\"t\",\"T\",\"take\",\"than\",\"that\",\"that's\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"therefore\",\"there's\",\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"this\",\"those\",\"though\",\"three\",\"through\",\"thus\",\"to\",\"together\",\"too\",\"toward\",\"two\",\"u\",\"U\",\"under\",\"until\",\"up\",\"upon\",\"us\",\"v\",\"V\",\"very\",\"w\",\"W\",\"was\",\"wasn't\",\"we\",\"we'd\",\"we'll\",\"well\",\"we're\",\"were\",\"weren't\",\"we've\",\"what\",\"what's\",\"when\",\"when's\",\"where\",\"where's\",\"whether\",\"which\",\"while\",\"who\",\"whole\",\"whom\",\"who's\",\"whose\",\"why\",\"why's\",\"will\",\"with\",\"within\",\"without\",\"won't\",\"would\",\"wouldn't\",\"x\",\"X\",\"y\",\"Y\",\"yet\",\"you\",\"you'd\",\"you'll\",\"your\",\"you're\",\"yours\",\"yourself\",\"yourselves\",\"you've\",\"z\",\"Z\",\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"a\",\"A\"}\n",
    "\n",
    "# to remove STOPWORDS from a list of strings\n",
    "def remove_stopwords(wordlist):\n",
    "    \"\"\" \n",
    "    It removes STOPWORDS from the list of strings 'wordlist'\n",
    "    \n",
    "    :param list_of_articles:\n",
    "        list of strings with STOPWORDS to remove \n",
    "    :return:\n",
    "        new list of strings without STOPWORDS\n",
    "    \"\"\"\n",
    "    return [w for w in wordlist if w not in STOPWORDS]\n",
    "\n",
    "# for testing \n",
    "remove_stopwords(str_no_punct.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WHASt3fbhuW1",
    "outputId": "b68499b5-202f-4e15-a4cd-b580bf8f769e"
   },
   "outputs": [],
   "source": [
    "# cleaning data\n",
    "def clean_data(content_to_clean):\n",
    "    \"\"\"\n",
    "    It performs text cleaning by converting text to lower case \n",
    "    and removing punctuation and stopwords\n",
    "    \n",
    "    :param content_to_clean:\n",
    "        str, string to clean\n",
    "    :return:\n",
    "        list, cleaned list of string (words) \n",
    "    \"\"\"\n",
    "    \n",
    "    # simple text normalization: string in lower case\n",
    "    content_to_clean = content_to_clean.lower()\n",
    "    # remove punctuations\n",
    "    no_punct_content = remove_punctuations(content_to_clean)\n",
    "    # get list of words\n",
    "    list_words = no_punct_content.split()\n",
    "    # remove stopwords\n",
    "    cleaned_content = remove_stopwords(list_words)\n",
    "    \n",
    "\n",
    "    return cleaned_content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data('Andrea likes pizza and Python!! and you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before cleaning')\n",
    "print(all_descriptions[:600])\n",
    "print()\n",
    "\n",
    "cleaned_content = clean_data(all_descriptions)\n",
    "\n",
    "print('After cleaning')\n",
    "print(cleaned_content[:200])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTJt_NnohuW0"
   },
   "source": [
    "## Compute word-frequency pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrx-UF-ehuW1"
   },
   "source": [
    "Let's compute the frequency of use of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Km1bimgBhuW2"
   },
   "outputs": [],
   "source": [
    "# computing word-frequency pairs\n",
    "def analyze_data(list_cleaned_content):\n",
    "    \"\"\"\n",
    "    It counts word frequency from 'list_cleaned_content' and makes a dictionary from it\n",
    "      \n",
    "    :param cleaned_content:\n",
    "        list, list of string to analyze\n",
    "    :return:\n",
    "        dictionary of word-frequency pairs\n",
    "    \"\"\"\n",
    "    \n",
    "    wordcount = {}\n",
    "    \n",
    "    for w in list_cleaned_content:\n",
    "        # check if the element exists in the dictionary\n",
    "        if w in wordcount: \n",
    "            wordcount[w] += 1 # increase the value present at the element key by 1\n",
    "        else:\n",
    "            wordcount[w] = 1 # add that element as key and set its value as 1\n",
    "            \n",
    "    return wordcount\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcount = analyze_data(cleaned_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the analysis in a Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "dig9Bd0ahuW2",
    "outputId": "c0579119-91d0-40ed-9768-a0d71a9509b5"
   },
   "outputs": [],
   "source": [
    "# visualizing the analysis in a Word Cloud\n",
    "def visualize_data(wordcount, max_words= 150):\n",
    "    \"\"\"\n",
    "    It plots word-frequency pairs as a Word Cloud \n",
    "    \n",
    "    :param wordcount:\n",
    "        list, dictionary of word-frequency pairs\n",
    "    :param max_words:\n",
    "        int, the maximum number of words\n",
    "    \"\"\"\n",
    "    # generates WordCloud image from wordcount\n",
    "    wc = WordCloud(width=1200,height=600, background_color='white', max_words = max_words).generate_from_frequencies(wordcount)\n",
    "    # shows WordCloud using MatPlotLib\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(wc)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data(wordcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZOihIUyhuW3"
   },
   "source": [
    "## Let's put everything in a function, so that we can run it easily for different sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aiLPRUQ-huW3"
   },
   "outputs": [],
   "source": [
    "def make_world_cloud(query,source,n_articles=50):\n",
    "    \"\"\"\n",
    "    Download relevant 'n_article' articles that contain 'query' from 'source' newspaper using NewsAPI\n",
    "    and plot a wordcloud with the most common words in the corpus.\n",
    "    \n",
    "    :param query: \n",
    "        Keywords or phrases to search for in the article title and body.\n",
    "    :param source: \n",
    "        the news source or blog you want headlines from\n",
    "    :param n_articles:\n",
    "        The number of articles to return (maximum 100)\n",
    "    \"\"\"\n",
    "    # 1.  Download all the articles the online service NewsAPI\n",
    "    articles = get_relevant_online_news(query=query, source=source, n_articles=n_articles)\n",
    "    \n",
    "    # 2. Combine the articles into one document (string)\n",
    "    contents = combine_articles(articles)\n",
    "    \n",
    "    # 3. cleaning data (lowecase, removing punctuations and stopwords)\n",
    "    cleaned_content = clean_data(contents)\n",
    "\n",
    "    # 4. computing word-frequency pairs\n",
    "    wordcount = analyze_data(cleaned_content)\n",
    " \n",
    "    # 5. Visualizing the analysis in a Word Cloud\n",
    "    visualize_data(wordcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "xHpV6Q20huW4",
    "outputId": "27ada0d5-37c5-4f00-9482-50d9a392b75a"
   },
   "outputs": [],
   "source": [
    "make_world_cloud('coronavirus','cnn',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "r4lb3NzahuW5",
    "outputId": "57b4833e-acfa-4b66-89d7-ac2fd63956fc"
   },
   "outputs": [],
   "source": [
    "make_world_cloud('coronavirus','bbc-news',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_world_cloud('coronavirus','the-verge',100)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copia di 05WordCloudCovid.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
